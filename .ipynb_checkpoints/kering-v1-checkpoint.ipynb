{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ef0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6df4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Downloads/archive/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9300e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).T\n",
    "\n",
    "x_train = data[1:]\n",
    "y_train = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be561543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # generating random values for each element of the array of the first layer\n",
    "    w1 = np.random.rand(10, 784)\n",
    "    b1 = np.random.rand(10, 1)\n",
    "    \n",
    "    # generating random values for the hidden layer of 10 neurons\n",
    "    w2 = np.random.rand(10, 10)\n",
    "    b2 = np.random.rand(10, 1)\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "# activation that returns only positive values\n",
    "def reLU(layer):\n",
    "    return np.maximum(0, layer)\n",
    "\n",
    "# activation that returns a number between 0 and 1\n",
    "def softmax(layer):\n",
    "    return np.exp(layer) / np.sum(np.exp(layer))\n",
    "\n",
    "# taking weights and biases plus the layer x to obtain \n",
    "def forward_prop(w1, b1, w2, b2, x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = reLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "# what the fuck is this doing? Creating a 0s matrix and substituting with 1 for some reason?\n",
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((y.size, y.max() + 1))\n",
    "    one_hot_y[np.arange(y.size), y] = 1\n",
    "    one_hot_y = one_hot_y.T\n",
    "    \n",
    "# derivative of reLU activation function\n",
    "def d_reLU(layer):\n",
    "    return layer > 0\n",
    "    \n",
    "# \n",
    "def back_prop(z1, a1, z2, a2, w2, x, y):\n",
    "    m = y.size\n",
    "    one_hot_y = one_hot(y)\n",
    "    print(one_hot_y)\n",
    "    print(a2-one_hot_y)\n",
    "    \"\"\"\"\"\"\n",
    "    d_z2 = a2 - one_hot_y\n",
    "    d_w2 = 1 / m * d_z2.dot(a1.T)\n",
    "    d_b2 = 1 / m * np.sum(d_z2, 2)\n",
    "    d_z1 = w2.T.dot(d_z2) * d_reLU(z1)\n",
    "    d_w1 = 1 / m * d_z1.dot(x.T)\n",
    "    d_b1 = 1 / m * np.sum(d_z1, 2)\n",
    "    return d_w1, d_b1, d_w2, d_b2\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "def update_params(w1, b1, w2, b2, d_w1, d_b1, d_w2, d_b2, alpha):\n",
    "    w1 = w1 - alpha * d_w1\n",
    "    b1 = b1 - alpha * d_b1\n",
    "    w2 = w2 - alpha * d_w2\n",
    "    b2 = b2 - alpha * d_b2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b445deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    print(predictions, y)\n",
    "    return np.sum(predictions == y)/y.size\n",
    "\n",
    "def grad_desc(x, y, iterations, alpha):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, x)\n",
    "        d_w1, d_b1, d_w2, d_b2 = back_prop(z1, a1, z2, a2, w2, x, y)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, d_2)\n",
    "        if i % 50 == 0:\n",
    "            print('Iteration ', i)\n",
    "            print('Accuracy ', get_accuracy(get_predictions(a2), y))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f3010dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-e28fe1663728>:18: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(layer) / np.sum(np.exp(layer))\n",
      "<ipython-input-25-e28fe1663728>:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(layer) / np.sum(np.exp(layer))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-02feb529ffff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-6416d7829933>\u001b[0m in \u001b[0;36mgrad_desc\u001b[0;34m(x, y, iterations, alpha)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0md_w1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_w2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-e28fe1663728>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(z1, a1, z2, a2, w2, x, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mone_hot_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0md_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mone_hot_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0md_w2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_z2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0md_b2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_z2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = grad_desc(x_train, y_train, 500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8b6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97da317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
